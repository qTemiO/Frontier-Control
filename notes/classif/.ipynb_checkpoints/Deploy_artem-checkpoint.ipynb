{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18a1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zhiti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import string\n",
    "import nltk\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk import word_tokenize\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords.extend(['…', '«', '»', '...', 'т.д.', 'т', 'д','а','и','\\n'])\n",
    "\n",
    "df_res = pd.read_csv(r'C:\\Users\\zhiti\\Documents\\GitHub\\Frontier-Control\\backend\\filter\\data\\user_dataframe.csv',sep=';',encoding='ANSI')\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "def remove_punctuation(text):\n",
    "    return \"\".join([ch if ch not in string.punctuation else ' ' for ch in text])\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text])\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "mystem = Mystem() \n",
    "\n",
    "russian_stopwords = nltk.corpus.stopwords.words('russian')\n",
    "russian_stopwords.extend(['…', '«', '»', '...', 'т.д.', 'т', 'д','а','и','\\n'])\n",
    "def lemmatize_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords and token != \" \"]\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = word_tokenize(text) \n",
    "    tokens = [token for token in tokens if token not in russian_stopwords and token != ' ']\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbbbce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_text = \"радиоактивные вещества \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117746dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'радиоактивный вещество'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_text = remove_multiple_spaces(remove_numbers(remove_punctuation(tech_text.lower())))\n",
    "tech_text = remove_stop_words(tech_text)\n",
    "tech_text = lemmatize_text(tech_text)\n",
    "tech_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55575698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('tnved_class.pkl', 'rb') as fid:\n",
    "    logreg = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9333a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(C=100000.0, n_jobs=1))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2bea5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.0025\n",
      "1    1702.0000\n",
      "Name: 136, dtype: float64\n",
      "0       0.0007\n",
      "1    1802.0000\n",
      "Name: 140, dtype: float64\n",
      "0       0.0293\n",
      "1    2101.0000\n",
      "Name: 159, dtype: float64\n",
      "0       0.0007\n",
      "1    2502.0000\n",
      "Name: 185, dtype: float64\n",
      "0       0.0015\n",
      "1    2828.0000\n",
      "Name: 270, dtype: float64\n",
      "0       0.9593\n",
      "1    2844.0000\n",
      "Name: 285, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "my_tags=df_res['TNVED'].unique()\n",
    "tech_pred = logreg.predict_proba([tech_text])\n",
    "res=pd.DataFrame([np.round(tech_pred[0],4),(my_tags).astype(float)])\n",
    "res\n",
    "\n",
    "zeros = []\n",
    "ones = []\n",
    "for index, row in res.iterrows():\n",
    "    if index == 0:\n",
    "        maxes = np.sort(row)[len(row)-5:]\n",
    "        \n",
    "for column in res.columns:\n",
    "    if res[column][0] in maxes:\n",
    "        print(res[column])\n",
    "\n",
    "data_res=pd.DataFrame()\n",
    "data_res['class']=my_tags\n",
    "data_res['predict']=np.round(tech_pred[0],4)\n",
    "predict =data_res.sort_values(by='predict',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2cb7a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': '2844', 'probility': 0.9593},\n",
       " {'class': '2101', 'probility': 0.0293},\n",
       " {'class': '1702', 'probility': 0.0025},\n",
       " {'class': '2828', 'probility': 0.0015},\n",
       " {'class': '1802', 'probility': 0.0007}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "autochecker = False\n",
    "for index, row in predict[:5].iterrows():\n",
    "    if not autochecker:\n",
    "        if row['predict'] > 0.99: \n",
    "            autochecker=True\n",
    "        if row['predict'] > 0.01:\n",
    "            results.append({'class':str(int(row['class'])), 'probility':row['predict']})\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
